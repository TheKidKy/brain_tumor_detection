{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b82a0-b697-4b62-992f-eed17e7616f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f1035b-0264-4730-a229-419cff2f3240",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff613ce-ab96-42d4-8226-d973983d7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = 'Dataset'\n",
    "\n",
    "# Load the full training dataset\n",
    "full_train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'Training'))\n",
    "\n",
    "# Split training data into train and validation (80% train, 20% val)\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_train_dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "# Create a copy of the validation dataset with val transforms\n",
    "val_dataset = torch.utils.data.Subset(\n",
    "    datasets.ImageFolder(os.path.join(data_dir, 'Training'), transform=data_transforms['val']),\n",
    "    val_dataset.indices\n",
    ")\n",
    "\n",
    "# Apply different transforms to train and val sets\n",
    "# For train set: keep the original transforms with augmentations\n",
    "# For val set: apply validation transforms (no augmentations)\n",
    "train_dataset.dataset.transform = data_transforms['train']\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset,\n",
    "    'test': datasets.ImageFolder(os.path.join(data_dir, 'Testing'), transform=data_transforms['test'])\n",
    "}\n",
    "\n",
    "print(full_train_dataset.classes)\n",
    "print('training images:', len(image_datasets['train']))\n",
    "print('validation images:', len(image_datasets['val']))\n",
    "print('testing images:', len(image_datasets['test']))\n",
    "\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=0),\n",
    "    'test': DataLoader(image_datasets['test'], batch_size=32, shuffle=False, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dabe2e-544c-4d51-bc89-130169a833b3",
   "metadata": {},
   "source": [
    "### Show Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b64c0-1f96-49fb-bac5-c2043c7f5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper to unnormalize images (since you applied ImageNet normalization)\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))   # C x H x W -> H x W x C\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std  = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean   # unnormalize\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Show a batch of images with augmentation\n",
    "def show_random_batch(dataloader, class_names, num_images=6):\n",
    "    inputs, classes = next(iter(dataloader))\n",
    "    out = torchvision.utils.make_grid(inputs[:num_images])  # take first N images\n",
    "    imshow(out, title=[class_names[x] for x in classes[:num_images]])\n",
    "\n",
    "# Example usage:\n",
    "show_random_batch(dataloaders['train'], image_datasets['train'].dataset.classes, num_images=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
